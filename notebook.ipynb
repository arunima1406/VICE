{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17203b01",
   "metadata": {},
   "source": [
    "Vehicle Insurance Cost Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c147afc",
   "metadata": {},
   "source": [
    "1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a5078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import ViTImageProcessor\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e4a82",
   "metadata": {},
   "source": [
    "2. Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8350943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train/train.csv\")\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Save (optional)\n",
    "train_df.to_csv('train_split.csv', index=False)\n",
    "test_df.to_csv('test_split.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c0a4a",
   "metadata": {},
   "source": [
    "3. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6676274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545151dd",
   "metadata": {},
   "source": [
    "4. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b0e71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDamageDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.loc[idx, 'filename']\n",
    "        label = int(self.df.loc[idx, 'label']) - 1  # convert to 0â€“5\n",
    "        image_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c88b2",
   "metadata": {},
   "source": [
    "    5. DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0378699",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CarDamageDataset(train_df, img_dir=\"data/train/images\", transform=transform)\n",
    "val_df = test_df.copy()\n",
    "val_dataset = CarDamageDataset(val_df, img_dir=\"data/train/images\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "class_names = ['crack', 'scratch', 'tire flat', 'dent', 'glass shatter', 'lamp broken']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da1d76d",
   "metadata": {},
   "source": [
    "6. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1f21256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([6]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([6, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224',\n",
    "    num_labels=6 ,\n",
    "    ignore_mismatched_sizes=True # since you have 6 classes\n",
    ")\n",
    "#optimizer, loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3093b87",
   "metadata": {},
   "source": [
    "7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fe7312c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 10\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(train_loader) * num_epochs\n",
    ") \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Wrap train_loader with tqdm for progress bar\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(pixel_values=images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update tqdm postfix to show loss dynamically\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8bb84",
   "metadata": {},
   "source": [
    "8. Model Evaluation and Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee0ad552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 97.92%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        crack       0.90      1.00      0.95        35\n",
      "      scratch       0.98      0.97      0.98       474\n",
      "    tire flat       1.00      0.96      0.98       104\n",
      "         dent       0.97      0.99      0.98       413\n",
      "glass shatter       1.00      0.99      0.99       233\n",
      "  lamp broken       0.98      0.98      0.98       181\n",
      "\n",
      "     accuracy                           0.98      1440\n",
      "    macro avg       0.97      0.98      0.98      1440\n",
      " weighted avg       0.98      0.98      0.98      1440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(pixel_values=images).logits\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Map back to original file names (order matches `test_df` due to DataLoader order)\n",
    "all_filenames = test_df['filename'].values.tolist()\n",
    "\n",
    "# Save predictions to CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'filename': all_filenames,\n",
    "    'true_label': all_labels,\n",
    "    'predicted_label': all_preds\n",
    "})\n",
    "\n",
    "results_df.to_csv(\"val_predictions.csv\", index=False)\n",
    "\n",
    "# Calculate accuracy (optional print)\n",
    "accuracy = (results_df['true_label'] == results_df['predicted_label']).mean() * 100\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bdc6b9",
   "metadata": {},
   "source": [
    "9. Save the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e63acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'car_damage_vit.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca62b0",
   "metadata": {},
   "source": [
    "metrics folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb7d0645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 97.99%\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        crack       0.90      1.00      0.95        35\n",
      "      scratch       0.98      0.97      0.98       474\n",
      "    tire flat       1.00      0.97      0.99       104\n",
      "         dent       0.97      0.99      0.98       413\n",
      "glass shatter       1.00      0.99      0.99       233\n",
      "  lamp broken       0.98      0.97      0.98       181\n",
      "\n",
      "     accuracy                           0.98      1440\n",
      "    macro avg       0.97      0.98      0.98      1440\n",
      " weighted avg       0.98      0.98      0.98      1440\n",
      "\n",
      "Metrics saved in folder: metrics_output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure model is in eval mode\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(pixel_values=images).logits\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Map back to filenames (make sure test_df is aligned with val_loader order)\n",
    "all_filenames = test_df['filename'].values.tolist()\n",
    "\n",
    "# Create directory to save metrics if it doesn't exist\n",
    "output_dir = \"metrics_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save predictions to CSV\n",
    "results_df = pd.DataFrame({\n",
    "    'filename': all_filenames,\n",
    "    'true_label': all_labels,\n",
    "    'predicted_label': all_preds\n",
    "})\n",
    "results_csv_path = os.path.join(output_dir, \"val_predictions.csv\")\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "\n",
    "# Generate classification report dictionary and text\n",
    "class_report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
    "class_report_text = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "# Save classification report text file\n",
    "report_path = os.path.join(output_dir, \"classification_report.txt\")\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(f\"Validation Accuracy: {accuracy:.2f}%\\n\\n\")\n",
    "    f.write(class_report_text)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "print(class_report_text)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save confusion matrix plot\n",
    "cm_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "plt.savefig(cm_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Metrics saved in folder: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
